{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gretel Synthetics Walkthrough\n",
    "\n",
    "Welcome to the Gretel Synthetics walkthrough! In this tutorial we will take you through the steps of extracting data from Gretel, building a training dataset, creating synthetic data, and validating the new data!\n",
    "\n",
    "This tutorial assumes you have already created and uploaded data to a [Gretel project](https://console.gretel.cloud).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "- If using Google Colab, we recommend you change to a GPU runtime. From the menu, choose \"Runtime\" and then choose \"Change runtime type\"\n",
    "\n",
    "- Input your Gretel URI String. Just run the cell below (no need to change it's contents) and then enter your Gretel URI in the pop-up box when it appears. \n",
    "\n",
    "- Create your Gretel Synthetic Configuration Template\n",
    "  - See [our documentation](https://gretel-synthetics.readthedocs.io/en/stable/api/config.html) for additional config options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "gretel_uri = os.getenv(\"GRETEL_URI\") or getpass.getpass(\"Your Gretel URI\")\n",
    "checkpoint_dir = str(Path.cwd() / \"checkpoints\")\n",
    "\n",
    "config_template = {\n",
    "    \"checkpoint_dir\": checkpoint_dir,\n",
    "    \"dp\": True, # enable differential privacy in training\n",
    "    \"epochs\": 15,\n",
    "    \"gen_lines\": 100,\n",
    "    \"max_lines\": 0,\n",
    "    \"max_line_len\": 2048,\n",
    "    \"overwrite\": True,\n",
    "    \"save_all_checkpoints\": False,\n",
    "    \"vocab_size\": 20000\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to create a synthetic dataset\n",
    "\n",
    "In the code below, we will:\n",
    "* Install Gretel packages and dependencies\n",
    "* Connect to Gretel API and download source data the project stream\n",
    "* Automatically build a record validator from the source data\n",
    "* Train a synthetic model (neural network) on the source data\n",
    "* Generate `gen_lines` synthetic data records that pass validation\n",
    "* Create a synthetic data performance report to compare the source and synthetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "gretel_synthetics_deps",
    "cell_replaced": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install -U gretel-client\n",
    "\n",
    "# NOTE: if you need synthetics, but already have TensorFlow installed (like in Colab) install below\n",
    "!pip install gretel-synthetics\n",
    "\n",
    "# NOTE: if you need synthetics AND TensorFlow, use the below\n",
    "# !pip install gretel-synthetics[tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "gretel_synthetics_boilerplate",
    "cell_replaced": true
   },
   "outputs": [],
   "source": [
    "from gretel_client import project_from_uri\n",
    "\n",
    "project = project_from_uri(gretel_uri)\n",
    "project.client.install_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select fields from source dataset\n",
    "\n",
    "By default we suggest filtering fields based on percent unique and percent missing. We reccomend using fields that have no more than 80% uniqueness and are missing no more than 20% of the time. Feel free to adjust these parameters.\n",
    "\n",
    "If you wish to use all fields, you can omit the returned ``include_fields`` list from the synthetic bundle creation below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_helpers.synthetics import create_bundle_from_project, filter_fields\n",
    "\n",
    "include_fields, drop_fields = filter_fields(project, max_unique_percent=80, max_missing_percent=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Gretel Synthetic Bundle\n",
    "\n",
    "Next, we run our bundle automation process. This automates the following actions:\n",
    "\n",
    "- Download records from your Gretel Project and convert them to a DataFrame\n",
    "- Adjust the fields to be used for synthesis\n",
    "- Automatically detect a field delimiter to be used for the Gretel Synthetics library\n",
    "- Automatically detect correlations between columns and create batches of column headers for synthesis\n",
    "- Build data validators that ensure generated records are within a range of boundaries learned from your training data\n",
    "- Build neural network models\n",
    "- Utilize AI models to create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = create_bundle_from_project(\n",
    "    project=project,\n",
    "    max_size=5000,\n",
    "    include_fields=include_fields,  # NOTE: you may omit this param to utilize all fields from your training data\n",
    "    synthetic_config=config_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle.training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle.get_synthetic_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Report\n",
    "\n",
    "The Performance Report compares the training data to the newly created synthetic data and assesses their statistical similarity.   It shows you both quantitatively and graphically any differences between within field distributions as well as cross field correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle.generate_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
