# fastinference
> A collection of inference modules for fastai including inference speedup and interpretability


## Install

We have 4 modules you can install, depending on your usecase:

* Base Library (Just inference stuff): `pip install fastinference`
* ONNX Inference: `pip install fastinference[onnx-cpu]` or `fastinference[onnx-gpu]`
* Interperatability (Class Confusion + SHAP): `pip install fastinference[interp]`
* Everything: `pip install fastinference[all]`

## Wonderful Contributors:

[![](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/images/0)](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/links/0)[![](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/images/1)](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/links/1)[![](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/images/2)](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/links/2)[![](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/images/3)](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/links/3)[![](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/images/4)](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/links/4)[![](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/images/5)](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/links/5)[![](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/images/6)](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/links/6)[![](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/images/7)](https://sourcerer.io/fame/muellerzr/muellerzr/fastinference/links/7)


# Directions for Contributing:

1. Fork this repository into your GitHub Account
2. Ensure that `nbdev` is installed on your system
3. Make any changes and ensure that you run the following **before** commiting:
  * `nbdev_build_lib`
  * `nbdev_clean_nbs`
4. Open a Pull Request with the library, and choose "From fork" to open one with the main repository.
