Metadata-Version: 2.1
Name: neuraxle_tensorflow
Version: 0.1.2
Summary: TensorFlow steps, savers, and utilities for Neuraxle. Neuraxle is a Machine Learning (ML) library for building neat pipelines, providing the right abstractions to both ease research, development, and deployment of your ML applications.
Home-page: https://github.com/Neuraxio/Neuraxle-Tensorflow
Author: Neuraxio Inc.
Author-email: guillaume.chevalier@neuraxio.com
License: Apache 2.0
Download-URL: https://github.com/Neuraxio/Neuraxle-Tensorflow/tarball/0.1.2
Description: # Neuraxle-TensorFlow
        
        TensorFlow steps, savers, and utilities for [Neuraxle](https://github.com/Neuraxio/Neuraxle).
        
        Neuraxle is a Machine Learning (ML) library for building neat pipelines, providing the right abstractions to both ease research, development, and deployment of your ML applications.
        
        ## Usage example
        
        [See also a complete example](https://github.com/guillaume-chevalier/seq2seq-signal-prediction)
        
        ### Tensorflow 1
        
        Create a tensorflow 1 model step by giving it a graph, an optimizer, and a loss function. 
        
        ```python
        def create_graph(step: TensorflowV1ModelStep, context: ExecutionContext):
            tf.placeholder('float', name='data_inputs')
            tf.placeholder('float', name='expected_outputs')
        
            tf.Variable(np.random.rand(), name='weight')
            tf.Variable(np.random.rand(), name='bias')
            
            return tf.add(tf.multiply(step['data_inputs'], step['weight']), step['bias'])
            
        """
        # Note: you can also return a tuple containing two elements : tensor for training (fit), tensor for inference (transform)
        def create_graph(step: TensorflowV1ModelStep, context: ExecutionContext)
            # ...
            decoder_outputs_training = create_training_decoder(step, encoder_state, decoder_cell)
            decoder_outputs_inference = create_inference_decoder(step, encoder_state, decoder_cell)
        
            return decoder_outputs_training, decoder_outputs_inference
        """
        
        
        def create_loss(step: TensorflowV1ModelStep, context: ExecutionContext):
            return tf.reduce_sum(tf.pow(step['output'] - step['expected_outputs'], 2)) / (2 * N_SAMPLES)
        
        def create_optimizer(step: TensorflowV1ModelStep, context: ExecutionContext):
            return tf.train.GradientDescentOptimizer(step.hyperparams['learning_rate'])
        
        model_step = TensorflowV1ModelStep(
            create_grah=create_graph,
            create_loss=create_loss,
            create_optimizer=create_optimizer,
            has_expected_outputs=True
        ).set_hyperparams(HyperparameterSamples({
            'learning_rate': 0.01
        })).set_hyperparams_space(HyperparameterSpace({
            'learning_rate': LogUniform(0.0001, 0.01)
        }))
        ```
        
        ### Tensorflow 2
        
        Create a tensorflow 2 model step by giving it a model, an optimizer, and a loss function. 
        
        ```python
        def create_model(step: Tensorflow2ModelStep, context: ExecutionContext):
            return LinearModel()
        
        def create_optimizer(step: Tensorflow2ModelStep, context: ExecutionContext):
            return tf.keras.optimizers.Adam(0.1)
        
        def create_loss(step: Tensorflow2ModelStep, expected_outputs, predicted_outputs):
            return tf.reduce_mean(tf.abs(predicted_outputs - expected_outputs))
        
        model_step = Tensorflow2ModelStep(
            create_model=create_model,
            create_optimizer=create_optimizer,
            create_loss=create_loss,
            tf_model_checkpoint_folder=os.path.join(tmpdir, 'tf_checkpoints')
        )
        ```
        
        ### Deep Learning Pipeline
        
        ```python
        batch_size = 100
        epochs = 3
        validation_size = 0.15
        max_plotted_validation_predictions = 10
        
        seq2seq_pipeline_hyperparams = HyperparameterSamples({
            'hidden_dim': 100,
            'layers_stacked_count': 2,
            'lambda_loss_amount': 0.0003,
            'learning_rate': 0.006,
            'window_size_future': sequence_length,
            'output_dim': output_dim,
            'input_dim': input_dim
        })
        feature_0_metric = metric_3d_to_2d_wrapper(mean_squared_error)
        metrics = {'mse': feature_0_metric}
        
        signal_prediction_pipeline = Pipeline([
            TrainOnly(DataShuffler()),
            WindowTimeSeries(),
            MeanStdNormalizer(),
            MiniBatchSequentialPipeline([
                Tensorflow2ModelStep(
                    create_model=create_model,
                    create_loss=create_loss,
                    create_optimizer=create_optimizer,
                    print_loss=True
                ).set_hyperparams(seq2seq_pipeline_hyperparams)
            ])
        ])
        
        pipeline, outputs = pipeline.fit_transform(data_inputs, expected_outputs)
        ```
        
Keywords: pipeline pipelines data science machine learning deep learning
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Financial and Insurance Industry
Classifier: Intended Audience :: Healthcare Industry
Classifier: Intended Audience :: Information Technology
Classifier: Intended Audience :: Manufacturing
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: System Administrators
Classifier: Intended Audience :: Telecommunications Industry
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Natural Language :: English
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Topic :: Adaptive Technologies
Classifier: Topic :: Office/Business
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Artificial Life
Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: Topic :: Scientific/Engineering :: Interface Engine/Protocol Translator
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Scientific/Engineering :: Medical Science Apps.
Classifier: Topic :: Scientific/Engineering :: Physics
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Assemblers
Classifier: Topic :: Software Development :: Build Tools
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Software Development :: Pre-processors
Classifier: Topic :: Software Development :: Quality Assurance
Classifier: Topic :: Software Development :: Testing
Classifier: Topic :: System
Classifier: Topic :: Text Processing
Classifier: Topic :: Text Processing :: Filters
Classifier: Topic :: Text Processing :: Linguistic
Classifier: Topic :: Utilities
Classifier: Typing :: Typed
Description-Content-Type: text/markdown
